# Lens Beyond Surface: Case Study Content

## Hero Section
**Title:** Lens Beyond Surface: Designing Ethical Storytelling Through AI & UX
**Subtitle:** A civic design partnership with Eater SF (Vox Media) exploring how visual design can reveal bias and reclaim authentic representation for LGBTQ+ communities in San Francisco.

**Meta Information:**
- **Role:** Product Designer & UX Researcher
- **Duration:** Fall 2023 - Spring 2024
- **Team:** Alex Korablev, Aiman Afzal, Thuong Nguyen, Kai JÃ¼rimÃ¤e, Mark Ying
- **Partner:** Paolo Bicchieri, Reporter at Eater SF (Vox Media)
- **Institution:** Minerva University - FE51: Cornerstone Civic Project

## TL;DR Section
Lens Beyond Surface is a civic partnership with **Vox Media's Eater SF** that explored how **AI and UX design** can reshape representation of marginalized communities. Through **research, prototyping, and visual storytelling**, our team designed an interactive concept that juxtaposes **AI-generated and real portraits** to expose bias and empower authentic storytelling.

**Key Highlights:**
- ðŸ§© Conducted UX research & ethical design investigation on AI representation gaps
- ðŸŽ¨ Prototyped a storytelling interface showing AI vs Real portraits
- ðŸ—£ï¸ Collaborated with Eater SF and SF AIDS Foundation on inclusive design
- ðŸš€ Presented at Minerva's Civic Symposium, sparking discussion on ethical AI

## Problem & Context

### The Challenge
San Francisco is celebrated as a sanctuary for LGBTQ+ communities, yet despite this reputation, the city's LGBTQ+ residentsâ€”particularly those living with STDsâ€”face persistent stigmatization in media narratives and healthcare settings. According to Mission Local (2023), 87% of LGBTQ+ residents reported negative experiences within mainstream health care settings, including shaming, judgment, and inadequate care.

### The AI Bias Problem
As AI-generated imagery becomes increasingly prevalent in media and journalism, these tools often amplify existing stereotypes rather than challenge them. When prompted with terms like "HIV," "gay man with STD," or "LGBTQ+ health," AI image generators like DALL-E and Craiyon produce distorted, harmful visual tropes that perpetuate stigma and misrepresentation.

### Design Question
> *How might we design a platform that reclaims narrative control and visual dignity for LGBTQ+ San Franciscans by exposing bias and amplifying real voices?*

### Stakeholders
- **Civic Partner:** Paolo Bicchieri, Reporter at Eater SF (Vox Media)
- **Community Partner:** Baruch Porras Hernandez, SF AIDS Foundation (Strut)
- **Target Users:** LGBTQ+ individuals willing to share stories, and general audiences consuming online visual journalism
- **Secondary Users:** Journalists, educators, and advocacy organizations

## Research & Discovery

### Research Methods
1. **Qualitative Interviews:** Conducted interviews with community members, journalists, and advocacy organizations
2. **AI Bias Analysis:** Tested multiple AI image generation tools with various prompts related to LGBTQ+ identity and health
3. **Secondary Research:** Reviewed academic literature on AI bias, counter-narration, and visual storytelling
4. **Ethical Design Consultations:** Collaborated with SF AIDS Foundation on inclusive design practices

### Key Insights

**Insight 1: Bias in AI is Visible and Harmful**
AI tools consistently generated violent, distorted, or stereotypical images when prompted with LGBTQ+ health-related terms. These images reinforced harmful narratives of illness, isolation, and deviance.

**Insight 2: People Crave Narrative Control**
Participants valued owning their story and being represented authentically, not through algorithmic interpretation. They wanted to challenge the "single story" that AI perpetuates.

**Insight 3: Trust Grows Through Transparency**
Explaining AI limitations and bias mechanisms built empathy and understanding among test users. Transparency about how AI works was crucial for the platform's credibility.

**Insight 4: Visual Comparison is Powerful**
Side-by-side comparisons of AI-generated vs. authentic portraits created immediate emotional impact and sparked critical thinking about representation.

### Design Takeaway
The product must both **reveal bias** and **enable human-centered storytelling**â€”a dual experience of awareness and agency.

## Ideation & Concept Development

### Initial Ideas
1. **Educational Microsite on AI Bias:** Focus on explaining how AI perpetuates stereotypes
2. **Visual Storytelling Blog:** Traditional article format with embedded images and narratives
3. **Interactive Gallery:** Compare "AI vs Real" portraits with interactive elements

### Chosen Direction
We selected the **Interactive Storytelling Platform** approach because it:
- Combined UX storytelling, AI ethics, and visual interaction
- Aligned with Eater SF's journalistic approach to public education
- Created an immersive experience that fostered empathy and critical thinking
- Allowed for scalability and future expansion

### Platform Features
- **Split-Screen Comparison:** View AI-generated vs authentic portraits side-by-side
- **First-Person Narratives:** Read authentic stories about identity, stigma, and resilience
- **Bias Explainers:** Learn about the mechanisms behind AI bias
- **Community Resources:** Access support organizations and educational materials

## Design Process

### Information Architecture
The platform was structured around three main sections:
1. **Stories:** Individual narratives and community context
2. **Compare:** AI vs Real slider interaction with bias explainers
3. **Learn:** Educational content about AI bias and community resources

### User Flow
The user journey was designed to create a progressive revelation experience:
1. **Entry Point:** Landing page with project introduction
2. **Exposure to Bias:** View AI-generated image and biased narrative
3. **Reveal Reality:** Discover real photograph and authentic story
4. **Education:** Explore resources and learn about AI bias
5. **Action:** Share or explore more stories

### Visual Design System

**Color Palette:**
- **Primary Red (#E63946):** Eater SF brand alignment, used for AI-generated content warnings
- **Teal (#2A9D8F):** Authentic stories and positive actions
- **Warm Orange (#F4A261):** Transition and comparison elements
- **Navy (#1D3557):** Navigation and structural elements
- **Neutral Grays:** Background and text

**Typography:**
- **Headings:** Clean sans-serif for journalistic trust
- **Body Text:** Readable serif for long-form narratives
- **Accessibility:** WCAG AA compliant contrast ratios

**Layout Principles:**
- **Split-Screen Design:** Visual separation between AI and reality
- **Progressive Disclosure:** Information revealed as user scrolls
- **Mobile-First:** Responsive design for all devices

## Prototyping & Iteration

### Low-Fidelity Wireframes
Created paper sketches and digital wireframes to test:
- Navigation structure
- Content hierarchy
- Interaction patterns
- Mobile responsiveness

### Mid-Fidelity Prototype
Developed interactive prototypes with:
- Compare slider interaction (AI vs Real)
- Pop-up explanations ("Why does AI show this?")
- "Learn More" cards linking to community resources
- Accessibility features (alt text, content warnings, tone sensitivity)

### User Testing
Conducted feedback sessions with:
- Journalists and faculty
- Volunteers from Strut SF (SF AIDS Foundation)
- Minerva University peers

### Key Changes from Testing

**Change 1: Reduced Emotional Load**
- **Before:** Stark, confrontational presentation of AI bias
- **After:** Softened prompts and added content warnings for emotional safety

**Change 2: Reframed Call-to-Action**
- **Before:** "See the Truth" (felt judgmental)
- **After:** "Explore Perspectives" (more inviting and empathetic)

**Change 3: Mobile Optimization**
- **Before:** Side-by-side layout only
- **After:** Vertical stacking for mobile with clear visual separation

**Change 4: Added Context**
- **Before:** Images without explanation
- **After:** Bias explainers and educational pop-ups

### Testing Results
Users reported feeling **informed, not overwhelmed** and said they would "trust" this platform more than AI-generated media. The progressive revelation approach was particularly effective in creating empathy without causing emotional distress.

## Community Engagement

### Recruitment Challenges
Recruiting participants for such a sensitive topic proved challenging. We:
- Partnered with SF AIDS Foundation's Strut program
- Created community flyers with QR codes
- Offered financial incentives ($20 Amazon gift cards)
- Distributed flyers in Castro district and LGBTQ+ community centers

### Ethical Considerations
- **IRB Exempt Status:** Ensured ethical research practices
- **Informed Consent:** Clear explanation of project goals and data use
- **Right to Withdraw:** Participants could exit at any time
- **Privacy Protection:** Alternative names and photo permissions
- **Sensitive Language:** Inclusive, respectful terminology throughout

## Final Outcome

### Deliverable
An interactive web prototype and storytelling framework presented at the **Minerva LBS Symposium 2024**.

### Platform Features
- **Real User Narratives:** Authentic stories paired with photographs
- **AI Comparison:** Side-by-side view of AI-generated vs. real images
- **Hover-Based Insights:** Educational explanations on demand
- **Modular Design:** Scalable framework for future expansion
- **Accessibility:** WCAG AA compliant with screen reader support

### Impact
- ðŸ§  **Increased Awareness:** Sparked dialogue about AI bias among student and journalistic audiences
- ðŸ¤ **Fostered Collaboration:** Strengthened connections between media and advocacy groups
- ðŸ’¬ **Inspired Future Work:** Eater SF expressed interest in exploring ethical design in visual journalism
- ðŸ“š **Educational Resource:** Prototype used as teaching tool for AI ethics discussions

## Design System Snapshot

### Components
- **Typography Scale:** Hierarchical system for headings, body text, and captions
- **Button Styles:** Primary (red), secondary (teal), tertiary (neutral)
- **Card Components:** Story cards, comparison cards, resource cards
- **Compare Slider UI:** Interactive element for AI vs Real comparison
- **Modal Pop-ups:** Bias explainers and educational content

### Accessibility Features
- **Color Contrast:** WCAG AA compliant ratios
- **Alt Text:** Descriptive text for all images
- **Keyboard Navigation:** Full keyboard accessibility
- **Screen Reader Support:** Semantic HTML and ARIA labels
- **Content Warnings:** Clear indicators for sensitive content

## Results & Reflections

### Key Outcomes
1. **Brought Attention to Underrepresented Voices:** Platform centered marginalized narratives
2. **Reframed AI Bias as Design Challenge:** Shifted conversation from data problem to design accountability
3. **Presented Design as Advocacy:** Demonstrated how empathy-driven interface design can challenge harmful narratives
4. **Created Scalable Framework:** Modular design allows for future expansion and adaptation

### Personal Reflection
> "This project reshaped how I define UXâ€”it's not just usability; it's accountability. Design can challenge narratives, not just beautify them. Working with Eater SF and the SF AIDS Foundation taught me that the most impactful design work happens at the intersection of technology, ethics, and human dignity."

### What I Learned
- **Ethical Design Requires Collaboration:** Working with community partners was essential for authentic representation
- **Transparency Builds Trust:** Explaining AI limitations helped users understand and engage critically
- **Design Can Be Advocacy:** Visual storytelling has the power to challenge systemic bias
- **Iteration is Essential:** User feedback transformed the project from confrontational to empathetic

## Next Steps

### Future Enhancements
1. **Expand Story Collection:** Recruit more participants and diversify narratives
2. **Public Launch:** Refine prototype for public hosting with full accessibility compliance
3. **Eater SF Integration:** Explore integration with Eater SF editorial formats
4. **Educational Toolkit:** Develop resources for educators and journalists
5. **API Integration:** Connect with community resources and support organizations

### Potential Impact
- **Media Literacy:** Help audiences critically evaluate AI-generated content
- **Journalism Ethics:** Influence how media organizations approach AI in visual storytelling
- **Community Empowerment:** Provide platform for marginalized voices to reclaim narratives
- **Policy Influence:** Contribute to conversations about AI regulation and ethical guidelines

